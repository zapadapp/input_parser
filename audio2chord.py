import os
import librosa
import numpy as np
import librosa.display
from scipy.signal import find_peaks
from scipy.fft import fft
import tensorflow as tf
from music21 import chord
from music21 import stream as m21stream
from array import ArrayType
import keras
import librosa
from sklearn.model_selection import train_test_split
import tensorflow as tf

# solve local imports
import sys
FILE_PATH = os.path.dirname(os.path.realpath(__file__))
WORKSPACE = os.path.dirname(FILE_PATH)

sys.path.insert(0, os.path.join(WORKSPACE, "chord_cnn"))
from parser_data import normalizeShape, correctShape


CATEGORIES = [
    "C4",
    "C4",
    "Mayor-DOs",
    "Mayor-FA",
    "Mayor-LA",
    "Mayor-MI",
    "Mayor-MIb",
    "Mayor-RE",
    "Mayor-SI",
    "Mayor-SIb",
    "Mayor-SOL",
    "Mayor-SOLs",
    "Menor-DO",
    "Menor-DOs",
    "Menor-FA",
    "Menor-FAs",
    "Menor-LA",
    "Menor-MI",
    "Menor-MIb",
    "Menor-RE",
    "Menor-SI",
    "Menor-SIb",
    "Menor-SOL",
    "Menor-SOLs"
]

chord_model = keras.models.load_model('/home/maxo/workspace/chord_cnn/modelo-acordes-v01.h5')

## Function that filters lower samples generated by input noise.
def filterLowSamples(samples):
    # find indexes of all elements lower than 2000 from samples
    indexes = np.where(samples < 2000)

    # remove elements for given indexes
    return np.delete(samples, indexes)

def detectAndPrintChord(s,q, y, sr, samples, a, b, scorePath):
    # limit the audio input from sample in index a to sample in index b, unless b is 999 which means that it is the end of the audio data
    if b == 999:
        data = y[samples[a]:]
    else:    
        data = y[samples[a]:samples[b]]
    
    # extract Chroma
    # extract Chroma
    chroma = librosa.feature.chroma_cens(y=data, sr=sr)
    if not correctShape(chroma.shape[1]) :
        chroma = normalizeShape(chroma)
    
    chroma_reshape = tf.reshape(chroma, [ 1,12,130])
    my_prediction = chord_model.predict(chroma_reshape)
    print(my_prediction)
    index = np.argmax(my_prediction)
    print("chord: " + CATEGORIES[index])
    playedChord = CATEGORIES[index]
    q.put(playedChord)
    if playedChord == "C4":
        s.append(chord.Chord(['C4','E4','G4']))
    print(s.write('lily.png', fp=os.path.join("tmp", scorePath)))
    #q.put(s)
    #print("Detected note: {}".format(str(librosa.hz_to_note(f[peak_i[0]]))))
    return 

    #print("No detected note")    



def processAudio(s,q, audioPath, scorePath):
    ############################################################
    ##############    Actual audio processing    ###############
    ############################################################

    # Note: we should be doing this in another thread so that we do not have to wait for this to finish to record another wave file.
    
    y, sr = librosa.load(audioPath)
    # generate image showing the audio input with the onset times
    #plt.figure(figsize=(14, 5))
    #librosa.display.waveshow(y, sr)

    onset_frames = librosa.onset.onset_detect(y, sr=sr, wait=1, pre_avg=1, post_avg=1, pre_max=1, post_max=1)
    #onset_times = librosa.frames_to_time(onset_frames)
    
    #plt.vlines(onset_times, -0.8, 0.79, color='r', alpha=0.8) 
    #plt.savefig(image_path)
    # plt.show()
    # plt.close()

    # convert frames to samples
    samples = librosa.frames_to_samples(onset_frames)

    # filter lower samples
    filteredSamples = filterLowSamples(samples)

    # get indexes of all samples in the numpy array
    indexes = np.where(filteredSamples>0)

    length = len(indexes[0])
    j = 0

    # iterate over all indexes of the onsets. What we do here is group indexes by two, so that we have the beginning and ending of 
    # the audio sample that we will use to get the note from.
    # For example, if we have 4 onsets (indexes 0 to 3) we use these segments:
    # 0 to 1
    # 1 to 2
    # 2 to 3
    # Next step: we should also use whatever piece of audio before the first index and after the last one.
    for i in indexes[0]:
        j = i
        
        if j < length-1:
            detectAndPrintChord(s, q, y, sr, filteredSamples, j, j+1, scorePath)
        elif j == length-1:
            detectAndPrintChord(s, q, y, sr, filteredSamples, j, 999, scorePath)
